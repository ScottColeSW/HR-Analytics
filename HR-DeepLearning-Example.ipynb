{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10f3152-f7ed-4178-9729-92161025d19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from tensorflow.python.util import module_wrapper as deprecation\n",
    "except ImportError:\n",
    "    from tensorflow.python.util import deprecation_wrapper as deprecation\n",
    "deprecation._PER_MODULE_WARNING_LIMIT = 0\n",
    "\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "tf.compat.v1.logging.set_verbosity(False)\n",
    "\n",
    "# load data into a dataframe\n",
    "data = pd.read_csv(\"./data/hr-formula-analytics-in-action.csv\")\n",
    "data.head()\n",
    "# Example data used to create test and training sets:\n",
    "# Employee_ID\tEmployees_Left\tAvg_Employees\tEngaged_Employees\tRecruitment_Costs\tHires\tEmployees_Lacking_Skills\tGender\tCity\tJob_Title\tDepartment\tStore_Location\tBusiness_Unit\tDivision\tAge\tLength_of_Service\tAbsent_Hours\tPerformance_Rating\tEducation_Level\tTraining_Hours\tSatisfaction_Score\tRetention_Rate\tAverage_Employee_Tenure\tAbsenteeism_Rate\tDiversity_Index\tTurnover_Rate\tEngagement_Score\tCost_Per_Hire\tSkills_Gap_Percentage\tRepresentation_Rate\n",
    "# 5\t100\t80\t5000\t10\t20\tM\tNY\tManager\tHR\tNY\tBU1\tD1\t45\t5\t10\t4\tBachelor's\t30\t75\t0.95\t4.8\t0.00125\t0.3\t0.05\t0.8\t500\t0.2\t0.003157895\n",
    "# 7\t120\t90\t6000\t12\t30\tF\tLA\tAnalyst\tFinance\tLA\tBU2\tD2\t30\t3\t5\t3\tMaster's\t20\t80\t0.941666667\t4.793103448\t0.000462963\t0.241666667\t0.058333333\t0.75\t500\t0.25\t0.002138643\n",
    "# 6\t110\t85\t5500\t11\t25\tM\tSF\tEngineer\tIT\tSF\tBU3\tD3\t35\t4\t8\t5\tHigh School\t25\t90\t0.945454545\t4.857142857\t0.000855615\t0.254545455\t0.054545455\t0.772727273\t500\t0.227272727\t0.002447552\n",
    "# 3\t105\t75\t4800\t9\t15\tF\tNY\tSpecialist\tMarketing\tNY\tBU1\tD1\t40\t6\t12\t4\tAssociate's\t15\t70\t0.971428571\t4.888888889\t0.00152381\t0.257142857\t0.028571429\t0.714285714\t533.3333333\t0.142857143\t0.002521008\n",
    "# 4\t95\t70\t4500\t8\t18\tM\tLA\tDeveloper\tIT\tLA\tBU3\tD3\t28\t2\t6\t3\tPhD\t40\t85\t0.957894737\t4.846153846\t0.000902256\t0.273684211\t0.042105263\t0.736842105\t562.5\t0.189473684\t0.003007519\n",
    "\n",
    "feats = ['Retention_Rate', 'Average_Employee_Tenure', 'Absenteeism_Rate', \n",
    "            'Diversity_Index', 'Turnover_Rate', 'Engagement_Score', 'Cost_Per_Hire', \n",
    "            'Skills_Gap_Percentage', 'Representation_Rate']\n",
    "\n",
    "# Encode categorical features using LabelEncoder\n",
    "categorical_features = ['Gender', 'City', 'Job_Title', 'Department', 'Store_Location', \n",
    "                        'Business_Unit', 'Division', 'Education_Level']\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "for feature in categorical_features:\n",
    "    data[feature] = label_encoder.fit_transform(data[feature])\n",
    "\n",
    "# separate categorical and numerical features\n",
    "numerical_features = data.select_dtypes(exclude=[\"object\", \"category\"]).columns\n",
    "\n",
    "# apply MinMaxScaler to numerical features\n",
    "scaler = MinMaxScaler()\n",
    "scaled_numerical_features = scaler.fit_transform(data[numerical_features])\n",
    "\n",
    "# combine encoded categorical and scaled numerical features\n",
    "encoded_data = np.concatenate([data[categorical_features].values, scaled_numerical_features], axis=1)\n",
    "\n",
    "# split encoded data into training and test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(encoded_data, data[feats], test_size=0.3, random_state=42)\n",
    "\n",
    "# define three different models to evaluate\n",
    "models = [\n",
    "    # model 1: simple multilayer perceptron\n",
    "    Sequential([\n",
    "        Dense(128, kernel_initializer='uniform', activation='relu', input_dim=x_train.shape[1]),\n",
    "        Dense(64, kernel_initializer='uniform', activation='relu'),\n",
    "        Dense(len(feats), kernel_initializer='uniform', activation='sigmoid')\n",
    "    ], name='MLP'),\n",
    "\n",
    "    # model 2: convolutional neural network (cnn)\n",
    "    Sequential([\n",
    "        Dense(128, kernel_initializer='uniform', activation='relu', input_dim=x_train.shape[1]),\n",
    "        Dense(64, kernel_initializer='uniform', activation='relu'),\n",
    "        Dense(32, kernel_initializer='uniform', activation='relu'),\n",
    "        Dense(len(feats), kernel_initializer='uniform', activation='sigmoid')\n",
    "    ], name='CNN'),\n",
    "\n",
    "    # model 3: recurrent neural network (rnn) - long short-term memory (lstm)\n",
    "    Sequential([\n",
    "        LSTM(128, return_sequences=True, input_shape=(x_train.shape[1], 1)),\n",
    "        LSTM(64),\n",
    "        Dense(len(feats), activation='sigmoid')\n",
    "    ], name='LSTM')\n",
    "]\n",
    "\n",
    "# evaluate and compare the performance of each model\n",
    "for model in models:\n",
    "    # compile the model\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    if model.name == 'LSTM':\n",
    "        # convert x_train and x_test to tensorflow tensors with float32 dtype\n",
    "        x_train_tensor = tf.convert_to_tensor(x_train, dtype=tf.float32)\n",
    "        y_train_tensor = tf.convert_to_tensor(y_train, dtype=tf.float32)\n",
    "        x_test_tensor = tf.convert_to_tensor(x_test, dtype=tf.float32)\n",
    "        y_test_tensor = tf.convert_to_tensor(y_test, dtype=tf.int64)\n",
    "\n",
    "        model.fit(x_train_tensor, y_train, batch_size=32, epochs=10, verbose=1)\n",
    "\n",
    "        # evaluate the model on the test set\n",
    "        test_loss, test_acc = model.evaluate(x_test_tensor, y_test, verbose=0)\n",
    "    else:\n",
    "        model.fit(x_train, y_train, batch_size=32, epochs=10, verbose=1)\n",
    "\n",
    "        # evaluate the model on the test set\n",
    "        test_loss, test_acc = model.evaluate(x_test, y_test, verbose=0)\n",
    "    \n",
    "    # print the model's performance\n",
    "    print(f\"model: {model.name}\")\n",
    "    print(f\"test loss: {test_loss:.4f}\")\n",
    "    print(f\"test accuracy: {test_acc:.4f}\")\n",
    "    print(\"-----------------------------------\")\n",
    "\n",
    "print(\"3 Models Created and Tested\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3511059-b2e2-4ac7-9436-ba701c991692",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "import pandas as pd\n",
    "\n",
    "# Load your data\n",
    "#df = pd.read_csv('your_data.csv')\n",
    "df = pd.read_csv(\"./data/hr-formula-analytics-in-action.csv\")\n",
    "\n",
    "# List of categorical columns to convert\n",
    "categorical_cols = ['Gender', 'City', 'Job_Title', 'Department', 'Store_Location', 'Business_Unit', 'Division', 'Education_Level']\n",
    "\n",
    "# Convert categorical columns to numerical\n",
    "le = LabelEncoder()\n",
    "for col in categorical_cols:\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "\n",
    "# List of columns to scale\n",
    "scale_cols = ['Employees_Left', 'Avg_Employees', 'Engaged_Employees', 'Recruitment_Costs', 'Hires', 'Employees_Lacking_Skills', 'Age', 'Length_of_Service', 'Absent_Hours', 'Performance_Rating', 'Training_Hours', 'Satisfaction_Score', 'Retention_Rate', 'Average_Employee_Tenure', 'Absenteeism_Rate', 'Diversity_Index', 'Turnover_Rate', 'Engagement_Score', 'Cost_Per_Hire', 'Skills_Gap_Percentage', 'Representation_Rate']\n",
    "\n",
    "# Scale the columns\n",
    "scaler = StandardScaler()\n",
    "df[scale_cols] = scaler.fit_transform(df[scale_cols])\n",
    "\n",
    "# Specify the number of clusters (k) you want to find\n",
    "k = 3\n",
    "\n",
    "# Perform K-Means clustering\n",
    "#kmeans = KMeans(n_clusters=k)\n",
    "kmeans = KMeans(n_clusters=k, init='k-means++', n_init=10, max_iter=100)\n",
    "labels = kmeans.fit_predict(df)\n",
    "kmeans.fit(df)\n",
    "\n",
    "# Get the cluster assignments for each data point\n",
    "clusters = kmeans.predict(df)\n",
    "\n",
    "# Add the cluster assignments to your original DataFrame\n",
    "df['Cluster'] = clusters\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6ec1f0-02f7-435f-9bb4-8d64b6473b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Filter rows of original data\n",
    "filtered_label0 = df[labels == 0]\n",
    "\n",
    "# Plotting the results\n",
    "plt.scatter(filtered_label0.iloc[:,0], filtered_label0.iloc[:,1])\n",
    "plt.show()\n",
    "\n",
    "# Filter rows of original data\n",
    "filtered_label2 = df[labels == 2]\n",
    "filtered_label8 = df[labels == 8]\n",
    "\n",
    "# Plotting the results\n",
    "plt.scatter(filtered_label2.iloc[:,0], filtered_label2.iloc[:,1], color='red')\n",
    "plt.scatter(filtered_label8.iloc[:,0], filtered_label8.iloc[:,1], color='black')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
